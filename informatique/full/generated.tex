%==============================================================
% Fichier généré automatiquement par `run.py,' ne pas modifier
%==============================================================

\part{Cours}

{
	\chap[-1]{Ordres et induction}
	\minitoc
	\renewcommand{\cwd}{../cours/chap-01/}
	\addmacros{
		\input{../cours/chap-01/l1.tex}
		\input{../cours/chap-01/l2.tex}
		\addrecap
	}
	\def\addmacros#1{#1}
}

{
	\chap[0]{Logique}
	\minitoc
	\renewcommand{\cwd}{../cours/chap00/}
	\addmacros{
		\input{../cours/chap00/l1.tex}
		\input{../cours/chap00/l2.tex}
		\input{../cours/chap00/l3.tex}
		\input{../cours/chap00/l4.tex}
		\input{../cours/chap00/l5.tex}
		\addrecap
	}
	\def\addmacros#1{#1}
}

{
	\chap[1]{Langages réguliers et Automates}
	\minitoc
	\renewcommand{\cwd}{../cours/chap01/}
	\addmacros{
		\input{../cours/chap01/l1.tex}
		\input{../cours/chap01/l2.tex}
		\input{../cours/chap01/l3.tex}
		\input{../cours/chap01/l4.tex}
		\input{../cours/chap01/l5.tex}
		\input{../cours/chap01/l6.tex}
		\input{../cours/chap01/l7.tex}
		\input{../cours/chap01/l8.tex}
		\input{../cours/chap01/l9.tex}
		\clearpage
		\setcounter{section}{0}		\renewcommand{\thesection}{\llap{Annexe }\thechapter.\Alph{section}}
		\renewcommand{\thesectionnum}{\Alph{section}}
		\input{../cours/chap01/a1.tex}
		\input{../cours/chap01/a2.tex}
	}
	\def\addmacros#1{#1}
}

{
	\chap[2]{Algorithmes probabilistes}
	\minitoc
	\renewcommand{\cwd}{../cours/chap02/}
	\addmacros{
		\input{../cours/chap02/l1.tex}
		\input{../cours/chap02/l2.tex}
		\input{../cours/chap02/l3.tex}
		\clearpage
		\setcounter{section}{0}		\renewcommand{\thesection}{\llap{Annexe }\thechapter.\Alph{section}}
		\renewcommand{\thesectionnum}{\Alph{section}}
		\input{../cours/chap02/a1.tex}
	}
	\def\addmacros#1{#1}
}

{
	\chap[3]{Apprentissage}
	\minitoc
	\renewcommand{\cwd}{../cours/chap03/}
	\addmacros{
		\input{../cours/chap03/l1.tex}
		\input{../cours/chap03/l2.tex}
		\input{../cours/chap03/l3.tex}
	}
	\def\addmacros#1{#1}
}

{
	\chap[4]{Calculabilité, Décidabilité, Complexité}
	\minitoc
	\renewcommand{\cwd}{../cours/chap04/}
	\addmacros{
		\input{../cours/chap04/l1.tex}
		\input{../cours/chap04/l2.tex}
		\input{../cours/chap04/l3.tex}
		\input{../cours/chap04/l4.tex}
		\input{../cours/chap04/l5.tex}
	}
	\def\addmacros#1{#1}
}

{
	\chap[5]{Trois exemples d'algorithmes de graphes}
	\minitoc
	\renewcommand{\cwd}{../cours/chap05/}
	\addmacros{
		\input{../cours/chap05/l1.tex}
		\input{../cours/chap05/l2.tex}
		\input{../cours/chap05/l3.tex}
		\input{../cours/chap05/l4.tex}
		\input{../cours/chap05/l5.tex}
		\input{../cours/chap05/l6.tex}
		\clearpage
		\setcounter{section}{0}		\renewcommand{\thesection}{\llap{Annexe }\thechapter.\Alph{section}}
		\renewcommand{\thesectionnum}{\Alph{section}}
		\input{../cours/chap05/a1.tex}
	}
	\def\addmacros#1{#1}
}

{
	\chap[6]{Preuves}
	\minitoc
	\renewcommand{\cwd}{../cours/chap06/}
	\addmacros{
		\input{../cours/chap06/l1.tex}
		\input{../cours/chap06/l2.tex}
		\input{../cours/chap06/l3.tex}
		\input{../cours/chap06/l4.tex}
		\input{../cours/chap06/l5.tex}
		\addrecap
	}
	\def\addmacros#1{#1}
}

{
	\chap[7]{Tentative de réponse à la \textbf{NP}-complétude}
	\minitoc
	\renewcommand{\cwd}{../cours/chap07/}
	\addmacros{
		\input{../cours/chap07/l1.tex}
		\input{../cours/chap07/l2.tex}
		\input{../cours/chap07/l3.tex}
		\clearpage
		\setcounter{section}{0}		\renewcommand{\thesection}{\llap{Annexe }\thechapter.\Alph{section}}
		\renewcommand{\thesectionnum}{\Alph{section}}
		\input{../cours/chap07/a1.tex}
	}
	\def\addmacros#1{#1}
}

{
	\chap[8]{Jeux}
	\minitoc
	\renewcommand{\cwd}{../cours/chap08/}
	\addmacros{
		\input{../cours/chap08/l1.tex}
		\input{../cours/chap08/l2.tex}
		\input{../cours/chap08/l3.tex}
	}
	\def\addmacros#1{#1}
}

{
	\chap[9]{Grammaires non contextuelles}
	\minitoc
	\renewcommand{\cwd}{../cours/chap09/}
	\addmacros{
		\input{../cours/chap09/l1.tex}
		\input{../cours/chap09/l2.tex}
		\input{../cours/chap09/l3.tex}
		\input{../cours/chap09/l4.tex}
		\input{../cours/chap09/l5.tex}
	}
	\def\addmacros#1{#1}
}

{
	\chap[10]{Concurrence}
	\minitoc
	\renewcommand{\cwd}{../cours/chap10/}
	\addmacros{
		\input{../cours/chap10/l1.tex}
		\input{../cours/chap10/l2.tex}
		\input{../cours/chap10/l3.tex}
		\input{../cours/chap10/l4.tex}
	}
	\def\addmacros#1{#1}
}



\part{Travaux Dirigés}
\def\prefix{\textsc{td}}
\renewcommand{\chaptername}{Travaux Dirigés}


{
	\td[1]{Ordre \& Induction}
	\minitoc
	\renewcommand{\cwd}{../td/td01/}
	\addmacros{
		\input{../td/td01/ex1.tex}
		\input{../td/td01/ex2.tex}
		\input{../td/td01/ex3.tex}
		\input{../td/td01/ex4.tex}
		\input{../td/td01/ex5.tex}
		\input{../td/td01/ex6.tex}
		\input{../td/td01/ex7.tex}
		\input{../td/td01/ex8.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[2]{Logique propositionnelle}
	\minitoc
	\renewcommand{\cwd}{../td/td02/}
	\addmacros{
		\input{../td/td02/ex1.tex}
		\input{../td/td02/ex2.tex}
		\input{../td/td02/ex3.tex}
		\input{../td/td02/ex4.tex}
		\input{../td/td02/ex5.tex}
		\input{../td/td02/ex6.tex}
		\input{../td/td02/ex7.tex}
		\input{../td/td02/ex8.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[3]{Langages et expressions régulières}
	\minitoc
	\renewcommand{\cwd}{../td/td03/}
	\addmacros{
		\input{../td/td03/ex1.tex}
		\input{../td/td03/ex10.tex}
		\input{../td/td03/ex11.tex}
		\input{../td/td03/ex12.tex}
		\input{../td/td03/ex2.tex}
		\input{../td/td03/ex3.tex}
		\input{../td/td03/ex4.tex}
		\input{../td/td03/ex5.tex}
		\input{../td/td03/ex6.tex}
		\input{../td/td03/ex7.tex}
		\input{../td/td03/ex8.tex}
		\input{../td/td03/ex9.tex}
		\input{../td/td03/exsup1.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[4]{Langages et expressions régulières (2)}
	\minitoc
	\renewcommand{\cwd}{../td/td04/}
	\addmacros{
		\input{../td/td04/ex01.tex}
		\input{../td/td04/ex02.tex}
		\input{../td/td04/ex03.tex}
		\input{../td/td04/ex04.tex}
		\input{../td/td04/ex05.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[5]{Langages et expressions régulières (3)}
	\minitoc
	\renewcommand{\cwd}{../td/td05/}
	\addmacros{
		\input{../td/td05/ex01.tex}
		\input{../td/td05/ex04.tex}
		\input{../td/td05/ex05.tex}
		\input{../td/td05/ex06.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[6]{Algorithmes probabilistes}
	\minitoc
	\renewcommand{\cwd}{../td/td06/}
	\addmacros{
		\input{../td/td06/ex01.tex}
		\input{../td/td06/ex02.tex}
		\input{../td/td06/ex03.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[7]{Décidabilité, Calculabilité}
	\minitoc
	\renewcommand{\cwd}{../td/td07/}
	\addmacros{
		\input{../td/td07/ex1.tex}
		\input{../td/td07/ex2.tex}
		\input{../td/td07/ex3.tex}
		\input{../td/td07/ex4.tex}
		\input{../td/td07/ex5.tex}
		\input{../td/td07/ex6.tex}
		\input{../td/td07/ex7.tex}
		\input{../td/td07/ex8.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[8]{Classe \textbf{P}, classe \textbf{NP}}
	\minitoc
	\renewcommand{\cwd}{../td/td08/}
	\addmacros{
		\input{../td/td08/ex1.tex}
		\input{../td/td08/ex2.tex}
		\input{../td/td08/ex3.tex}
		\input{../td/td08/ex4.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[9]{Algorithmique des graphes}
	\minitoc
	\renewcommand{\cwd}{../td/td09/}
	\addmacros{
		\input{../td/td09/ex1.tex}
		\input{../td/td09/ex2.tex}
		\input{../td/td09/ex3.tex}
		\input{../td/td09/ex4.tex}
		\input{../td/td09/ex5.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[10]{Preuves en logique propositionnelle}
	\minitoc
	\renewcommand{\cwd}{../td/td10/}
	\addmacros{
		\begin{landscape}
			\begin{multicols}{2}
				\input{../td/td10/ex1.tex}
				\input{../td/td10/ex2.tex}
			\end{multicols}
			\input{../td/td10/ex3.tex}
			\input{../td/td10/ex4.tex}
			\input{../td/td10/ex5.tex}
			\input{../td/td10/ex6.tex}
			\input{../td/td10/ex7.tex}
			\input{../td/td10/ex8.tex}
			\input{../td/td10/ex9.tex}
			\input{../td/td10/ex10.tex}
			\input{../td/td10/ex11.tex}
			\input{../td/td10/ex12.tex}
			\input{../td/td10/ex13.tex}
		\end{landscape}
	}
	\def\addmacros#1{#1}
}
{
	\td[11]{Preuves}
	\minitoc
	\renewcommand{\cwd}{../td/td11/}
	\addmacros{
		\input{../td/td11/ex1.tex}
		\input{../td/td11/ex2.tex}
		\input{../td/td11/ex3.tex}
		\input{../td/td11/ex4.tex}
		\input{../td/td11/ex5.tex}
		\input{../td/td11/ex6.tex}
		\input{../td/td11/ex7.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[12]{Algorithmes d'approximation}
	\minitoc
	\renewcommand{\cwd}{../td/td12/}
	\addmacros{
		\input{../td/td12/ex1.tex}
		\input{../td/td12/ex2.tex}
		\input{../td/td12/ex3.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[13]{Jeux}
	\minitoc
	\renewcommand{\cwd}{../td/td13/}
	\addmacros{
		\input{../td/td13/ex1.tex}
		\input{../td/td13/ex2.tex}
		\input{../td/td13/ex3.tex}
		\input{../td/td13/ex4.tex}
		\input{../td/td13/ex5.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[14]{Grammaires non contextuelles (1)}
	\minitoc
	\renewcommand{\cwd}{../td/td14/}
	\addmacros{
		\input{../td/td14/ex1.tex}
		\input{../td/td14/ex2.tex}
		\input{../td/td14/ex3.tex}
		\input{../td/td14/ex4.tex}
		\input{../td/td14/ex5.tex}
		\input{../td/td14/ex6.tex}
		\input{../td/td14/ex7.tex}
		\input{../td/td14/ex8.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[15]{Grammaires non contextuelles (2)}
	\minitoc
	\renewcommand{\cwd}{../td/td15/}
	\addmacros{
		\input{../td/td15/ex1.tex}
		\input{../td/td15/ex2.tex}
		\input{../td/td15/ex3.tex}
		\input{../td/td15/ex4.tex}
		\input{../td/td15/ex5.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[16]{Concurrence}
	\minitoc
	\renewcommand{\cwd}{../td/td16/}
	\addmacros{
		\input{../td/td16/ex1.tex}
		\input{../td/td16/ex2.tex}
		\input{../td/td16/ex3.tex}
		\input{../td/td16/ex4.tex}
		\input{../td/td16/ex5.tex}
	}
	\def\addmacros#1{#1}
}
{
	\td[17]{Concurrence}
	\minitoc
	\renewcommand{\cwd}{../td/td17/}
	\addmacros{
		\input{../td/td17/ex1.tex}
		\input{../td/td17/ex2.tex}
		\input{../td/td17/ex3.tex}
	}
	\def\addmacros#1{#1}
}
\def\prefix{\textsc{td bonus}}
{
	\td[1]{Complexité amortie}
	\minitoc
	\renewcommand{\cwd}{../td/td_b1/}
	\addmacros{
		\input{../td/td_b1/ex1.tex}
		\input{../td/td_b1/ex2.tex}
		\input{../td/td_b1/ex3.tex}
		\input{../td/td_b1/ex4.tex}
	}
	\def\addmacros#1{#1}
}
\def\prefix{\textsc{td bonus}}
{
	\td[2]{Diviser pour régner}
	\minitoc
	\renewcommand{\cwd}{../td/td_b2/}
	\addmacros{
		\input{../td/td_b2/ex1.tex}
		\input{../td/td_b2/ex2.tex}
	}
	\def\addmacros#1{#1}
}
\def\prefix{\textsc{td bonus}}
{
	\td[3]{Invariants plus complexes}
	\minitoc
	\renewcommand{\cwd}{../td/td_b3/}
	\addmacros{
	}
	\def\addmacros#1{#1}
}


\part{Travaux Pratiques}
\def\prefix{\textsc{tp}}
\renewcommand{\chaptername}{Travaux pratiques}


{
	\tp[1]{Logique propositionnelle}
	\minitoc
	\renewcommand{\cwd}{../tps/tp01/}
	\addmacros{
		\input{../tps/tp01/ex1.tex}
		\input{../tps/tp01/ex2.tex}
		\input{../tps/tp01/ex3.tex}
	}
	\def\addmacros#1{#1}
}
{
	% No `main.tex' file for tp02
	\def\addmacros#1{#1}
}
{
	\tp[3]{Langages et expressions régulières (2)}
	\minitoc
	\renewcommand{\cwd}{../tps/tp03/}
	\addmacros{
	}
	\def\addmacros#1{#1}
}
{
	% No `main.tex' file for tp04
	\def\addmacros#1{#1}
}
{
	% No `main.tex' file for tp05
	\def\addmacros#1{#1}
}
{
	% No `main.tex' file for tp06
	\def\addmacros#1{#1}
}
{
	\tp[7]{Algorithme de Kosaraju en \textsc{OCaml}}
	\minitoc
	\renewcommand{\cwd}{../tps/tp07/}
	\addmacros{
		\input{../tps/tp07/ex1.tex}
	}
	\def\addmacros#1{#1}
}
{
	% No `main.tex' file for tp08
	\def\addmacros#1{#1}
}
{
	% No `main.tex' file for tp09
	\def\addmacros#1{#1}
}
{
	% No `main.tex' file for tp10
	\def\addmacros#1{#1}
}
\def\prefix{\textsc{tp bonus}}
{
	% No `main.tex' file for tp_b1
	\def\addmacros#1{#1}
}
\def\prefix{\textsc{tp bonus}}
{
	% No `main.tex' file for tp_b2
	\def\addmacros#1{#1}
}


\part{Annexes}
\def\prefix{Annexe}
\renewcommand{\chaptername}{Annexe}
\useroman


{
	\chap[1]{Complexité amortie}
	\minitoc
	\renewcommand{\cwd}{../cours/annexeA/}
	\addmacros{
		Avec une fonction $\mathrm{PA}(n)$\/ ayant une complexité en $\mathcal{O}(f(n))$, on considère le problème ci-dessous.
		\begin{lstlisting}[language=caml]
			for i = 0 to n - 1 do
				%*$\mathrm{PA}$*)(i)
			done
		\end{lstlisting}
		Cet algorithme a une complexité en $\mathcal{O}(n f(n))$. Mais, parfois, cette complexité est trop approximative : parfois, des sommes mathématiques se compensent : \[
			\sum_{i=0}^{n-1} 2^i = 2^n \neq \cancel{\Theta}(n 2^n)
		.\]
	
		On considère le problème ci-dessous.
		\begin{lstlisting}[language=c]
			for (int i = 0; i < n; i = i + 1) (
				// calcul qui ne coute pas cher
			}
		\end{lstlisting}
		Le calcul \texttt{i = i + 1} est parfois plus coûteux que le calcul dans la boucle.
		Par exemple, un algorithme permettant de faire ce calcul est celui ci-dessous.
		\begin{algorithm}[H]
			\centering
			\begin{algorithmic}[1]
				\Entree un entier $n$, représenté sous la forme d'un tableau de \textit{bit} $T$\/ (où les \textit{bit}s de poids forts sont à droite
				\State $I \gets \mathrm{len}(T) - 1$\/ 
				\While{$T[I] = 1$}
				\State $T[I] \gets 0$
				\State $I \gets I - 1$
				\EndWhile
				\State $T[I] \gets 1$
			\end{algorithmic}
			\caption{Calcul de $n + 1$\/ avec un tableau de \textit{bit}s}
		\end{algorithm}
		Avec un tel algorithme, on a une complexité, dans le pire des cas, en $\Theta(\log_2 n)$.
		Ainsi, en modifiant le code, on peut avoir une complexité importante.
		\begin{lstlisting}[language=c]
			// n est une valeur donnee par l'utilisateur
			for (int i = 0; i < 2%*$^\texttt{n}$*); i = i + 1) (
				// calcul qui ne coute pas cher
			}
		\end{lstlisting}
		La complexité de cet algorithme, que l'on nommera $\mathcal{A}$\/ dans la suite,  est en $\mathcal{O}(\texttt{n}\:2^\texttt{n})$, car le \texttt{i = i + 1} coûte, au pire des cas, $\texttt{n}$.
		En réalisant des mesures, et en graphant le temps de cet algorithme divisé par $2^\texttt{n}$, on remarque que ce le ratio n'est pas une droite de coefficient directeur $\texttt{n}$, mais une constante (à partir d'un certain rang).
		On doit donc faire une étude plus précise de la complexité, et faire le calcul de la somme plus proprement.
		Une étude plus fine nous montre que l'algorithme est beaucoup plus long pour les entiers en plaisances de deux, mais les autres nombres, on n'a pas besoin d'autant de calcul.
		Faisons cette étude plus fine.
	
		On nomme $\mathcal{T}$\/ l'ensemble des tableaux de taille $n$\/ contenant des valeurs dans $\{0,1\}$. On a, \[
			\mathrm{Co\hat ut}_\mathcal{A}(n) = \sum_{t \in \mathcal{T}} \mathrm{Co\hat ut}_\text{Incr}(t)
		.\]Partitionnons $\mathcal{T}$\/ : \[
			\mathcal{T}_i = \Bigg\{
				\begin{array}{|c|c|c|c|c|c|}
					\hline
					\ldots & i + 1 & i & i - 1 & \ldots & 0\\ \hline
					\ldots & \mathbf{0} & \mathbf{1} & \mathbf{1} & \ldots & \mathbf{1}\\ \hline
				\end{array} \in \mathcal{T}
			\Bigg\}
		.\]  Si $t \in \mathcal{T}_i$, on sait que $\mathrm{Co\hat ut}_\text{Incr}(t) = i + 1$.
		Ainsi,
		\begin{align*}
			\sum_{t \in \mathcal{T}} \mathrm{Co\hat ut}_\text{Incr}(t)
			&= \sum_{i=0}^{n-1} \sum_{t \in \mathcal{T}_i} \mathrm{Co\hat ut}_\text{Incr}(t) \\
			&= \sum_{i=0}^{n-1} |\mathcal{T}_i| \cdot (i + 1) \\
			&= \sum_{i=0}^{n-1} 2^{n - 1 - i}\:(i+1) \\
			&= 2^n \sum_{i=1}^n \frac{i}{2^i}\\
			&= 2^n \times \mathcal{O}(1) \\
			&= \mathcal{O}(2^n) \\
		\end{align*}
		ce qui explique les résultats trouvés précédemment.
		L'incrementation \texttt{i = i + 1} est donc en $\mathcal{O}(1)$, et non en $\mathcal{O}(\log_2 \texttt{i})$.
	
		\begin{defn}
			Étant donnée une structure (des éléments d'un type de données abstrait,~\textsc{tda}), $\mathds{F}$, munie d'opérations $\mathds{O}$ opérant sur $\mathds{F}$\/ munis de fonctions de coût \[
				\forall o \in \mathds{O}, \quad C_o : \mathds{F} \to \R^+
			.\]
			Étant donné un élément initial $f_0 \in \mathds{F}$\/ et une suite d'opérations $(o_1, \ldots, o_n) \in \mathds{O}^n$, cela conduit donc à une suite d'éléments \[
				f_0 \overset{o_1}\leadsto f_1 \overset{o_2}\leadsto f_2 \leadsto \cdots \leadsto f_n.
			\] On appelle \textit{complexité} de cette séquence, notée $\tilde c$, \[
				\tilde C\big((o_1, \ldots, o_n), f_0\big)  = \sum_{i=0}^n C_{o_i}(f_{i-1})
			.\]
			On appelle alors \textit{complexité amortie} depuis $f_0 \in \mathds{F}$\/ la suite \[
				C_\mathrm{A}(f_0, n) = \frac{1}{n} \sup_{(o_1, \ldots, o_n) \in \mathds{O}^n} \tilde C\big((o_1, \ldots, o_n), f_0\big)
			.\]
		\end{defn}
	
		\begin{exm}[Tableaux dynamiques]
			On s'intéresse aux tableaux à longueur variable : on alloue un tableau de petite taille, et on alloue plus de mémoire au besoin.
			On a une structure de tableau dynamique :
			\begin{algorithm}[H]
				\centering
				\begin{algorithmic}[1]
					\State Soit $\mathrm{taille}' = f\big(\mathrm{len}(T)\big)$ \Comment{$f$ reste à déterminer}
					\State On alloue $T'$\/ de taille $\mathrm{taille}'$
					\State On recopie $T$\/ dans $T'$\/
					\State $T \gets T'$\/
				\end{algorithmic}
				\caption{$\textsc{Agrandit}(T)$, fonction agrandissant le tableau $t$\/}
			\end{algorithm}
			Cet algorithme a une complexité $\mathrm{Co\hat ut}_\textsc{Agrandit}(n) = n + f(n)$.
			On suppose que le tableau $T$\/ est rempli jusqu'à la $r$-ième case.
			\begin{algorithm}[H]
				\centering
				\begin{algorithmic}[1]
					\If{$\mathrm{len}(T) = r$}
					\State $\textsc{Agrandit}(T)$
					\EndIf
					\State $T[r] \gets x$
					\State $r \gets r + 1$
				\end{algorithmic}
				\caption{$\textsc{Ajout}(T,x)$, ajout d'un élément dans le tableau}
			\end{algorithm}
			On choisit la fonction $f$.
			\begin{description}
				\item[Cas 1] On choisit $f(n) = n + 1$. Soit une suite de $n$\/ opérations \textsc{Ajout} depuis un tableau de taille 1, où $r = 0$. Ainsi, \[
						f_0\overset{\textsc{Ajout}}\leadsto f_1 \overset{\textsc{Ajout}}\leadsto \cdots \leadsto f_i \leadsto \cdots \leadsto f_{n-1} \overset{\textsc{Ajout}}\leadsto f_n
					.\] La complexité de cette suite d'opérations est \[
						\tilde C\big((o_1, \ldots, o_n), f_0) = n + 2 \cdot \frac{n(n+1)}{2},
					\] d'où la complexité amortie est de $C_\mathrm{A}(f_0, n) = \Theta(n)$.
				\item[Cas 2] On choisit $f(n) = 2n$. On somme les complexités : $2n$\/ (clairement par dessin). Ainsi, $C_\mathrm{A}(f_0, n) = \Theta(1)$.
			\end{description}
		\end{exm}
	
		\begin{met}[du potentiel]
			Considérons une fonction $h : \mathds{F} \to \R^+$\/ dite \textit{de potentiel} telle que $h(f_0) = 0$.
			Intéressons nous alors à $\ubar{C}_o(f) = C_o(f) + h(\bar{f}) - h(f)$, où $f \overset o\leadsto \bar{f}$.
			Soit alors \[
				f_0 \overset{o_1}\leadsto f_1 \overset{o_1}\leadsto f_2 \leadsto \cdots \leadsto f_n
			\]une suite d'opérations. Alors,
			\begin{align*}
				\sum_{i=1}^n \ubar{C}_{o_i}(f_{i-1}) &= \sum_{i=1}^n \Big(C_{o_i}(f_{i-1}) + h(f_i) - h(f_{i-1})\Big)\\
				&= \bigg(\sum_{i=1}^n C_{o_i}(f_{i-1})\bigg) + \underbrace{h(f_n) - h(f_0)}_{\ge  0} \\
			\end{align*}
			par télescopage. Ainsi, \[
				\sum_{i=1}^n C_{o_i}(f_{i-1}) \le \sum_{i=1}^n \ubar{C}_{o_i}(f_{i-1})
			.\]
		\end{met}
	
		\begin{exm}
			On applique la méthode du potentiel au cas 2 de l'exemple ci-avant.
			On rappelle que $\mathds{F}$\/ est l'ensemble des tableaux. On pose la fonction \begin{align*}
				h: \mathds{F} &\longrightarrow \R^+ \\
				(T, r) &\longmapsto 6\left(r - \frac{\mathrm{len}(T)}{2}\right)
			\end{align*}
			Inspectons alors \[
				\ubar{C}_\textsc{Ajout}(T, r) = C_\textsc{Ajout}(\ubar{T}, \ubar{r}) + 6\bar{r} - 3\:\mathrm{len}(\bar{T}) - 3\ubar{r} + 3\:\mathrm{len}(\ubar{T})
			.\]
			Si $\mathrm{len}(\ubar{T}) = \ubar{r}$, alors $C_\textsc{Ajout}(\ubar{T}, \ubar{r}) = 3\:\mathrm{len}(\ubar{T})$\/ et $\mathrm{len}(\bar{T}) = 2\: \mathrm{len}(\ubar{T})$\/ et $\bar{r} = \ubar{r} + 1$.
			D'où, \[
				\ubar{C}_\textsc{Ajout}(\ubar{T}, \ubar{r}) = 3\:\mathrm{len}(\ubar{T}) + 6\ubar{r} + 6 - 6\:\mathrm{len}(\ubar{T}) - 6\ubar{r} + 3\:\mathrm{len}(\ubar{T}) = 6
			.\] 
			Sinon, $\mathrm{len}(\ubar{T}) > \ubar{r}$, alors $\mathrm{len}(\bar{T}) = \mathrm{len}(\ubar{T})$\/ et $\bar{r} = \ubar{r} + 1$.
			Ainsi,
			\begin{align*}
				\ubar{C}_\textsc{Ajout}(\ubar{T}, \ubar{r}) = 1 + 6 (\ubar{r} + 1) - 6\:\mathrm{len}(\bar{T}) - 6 \ubar{r} + 6\:\mathrm{len}(\ubar{T}) = 7
			\end{align*}
			D'où \[
				\sum_{i=1}^n C_{o_i}(f_{i-1}) \le \sum_{i=1}^n \ubar{C}_{o_i}(f_{i-1}) \le 7n
			.\] Le coût amorti est en $\mathcal{O}(1)$.
		\end{exm}
		\begin{exm}[Méthode du Banquier]
			On encode une file avec deux piles.
			Au moment de défiler, on doit potentiellement transvaser une pile dans une autre.
			Avec la méthode du Banquier, on a l'\textit{intuition} que le coût amorti est constant.
	
			On pose $\mathds{F}$\/ l'ensemble des couples de piles $(p_1, p_2)$.
			On a \[
				C_\text{défiler}\big((p_1, p_2)\big) = \begin{cases}
					\mathrm{taille}\ p_1 + 1 \quad& \text{si $p_2$ est vide}\\
					1 \quad& \text{ sinon}
				\end{cases}, \text{ et } C_\text{enfiler}\big((p_1, p_2)\big) = 1
			.\] Soit $h$\/ la fonction de potentiel définie comme \begin{align*}
				h: \mathds{F} &\longrightarrow \R^+ \\
				(p_1, p_2) &\longmapsto \mathrm{taille}\ p_1
			\end{align*}
			Étudions alors $\ubar{C}_\text{défiler}\big((p_1, p_2)\big)$.
			\begin{itemize}
				\item Si $p_2$\/ est vide, alors
					\begin{align*}
						\ubar{C}_\text{défiler}\big((p_1, p_2)\big) &= C_\text{défiler}\big((p_1,p_2)\big) + h\big((\bar{p}_1, \bar{p}_2)\big) - h\big((p_1, p_2)\big)\\
						&= \mathrm{taille} \ p_1 + 1 + \overbrace{\mathrm{taille}\ \bar{p}_1}^{=0} - \mathrm{taille}\ p_1 \\
						&= 1.
					\end{align*}
				\item Si $p_2$\/ n'est pas vide, alors \[
						\ubar{C}_\text{défiler}\big((p_1, p_2)\big) = 1 + \underbrace{\mathrm{taille}\  \bar{p}_1}_{\substack{\ds=\\ \ds \mathrm{taille}\ p_1}} - \mathrm{taille}\ p_1
					.\]
			\end{itemize}
			D'où, pour $(p_1, p_2) \in \mathds{F}$, $\ubar{C}_ \text{défiler}\big((p_1, p_2)\big) \le 1$.
			De plus,
			\begin{align*}
				\ubar{C}_ \text{ enfiler}\big((p_1, p_2)\big)
				&= C_ \text{enfiler}\big((p_1, p_2)\big) + h\big((\bar{p}_1, \bar{p}_2)\big) - h\big((p_1, p_2)\big) \\
				&= 1 + \mathrm{taille}\ \bar{p}_1 - \mathrm{taille}\ p_1 \\
				&= 2 \\
			\end{align*}
			Finalement, pour toute séquence d'opérations $o_1, \ldots, o_n$\/ initialisée à la file vide $f_0$, on a
			\begin{align*}
				\frac{1}{n} \tilde C\big((o_1,\ldots,o_n), f_0\big)
				&= \frac{1}{n} \sum_{i=0}^n C_{o_i}(f_{i-1}) \\
				&\le \frac{1}{n} \sum_{i=1}^n \ubar{C}_{o_i}(f_{i-1}) \\
				&\le 2
			\end{align*}
			D'où, un coût amorti constant.
		\end{exm}
	}
	\def\addmacros#1{#1}
}
{
	\chap[2]{Algorithmes \textsc{Dijkstra} et $A^*$}
	\minitoc
	\renewcommand{\cwd}{../cours/annexeB/}
	\addmacros{
		On s'intéresse, dans cette annexe, à l'algorithme $A^*$.
		Cette annexe se situe à l'intersection des chapitres sur les graphes, et sur les jeux.
		L'algorithme $A^*$ est une modification de l'algorithme de \textsc{Dijkstra}.
		Dans cette annexe, on prouvera la correction de l'algorithme $A^*$.
	
		On se place dans le contexte d'exécution d'un algorithme de calcul de plus cours chemin utilisant un tableau de distances $\mu$, et le manipulant en n'effectuant que des opérations \textsc{Relâcher}.
		Notons le graphe $G = (V,E)$, le sommet source $s$.
		Notons également $d(\cdot,\cdot)$ la distance induite par les arêtes du graphe $G$.
		De plus, on notera $c(\cdot,\cdot)$ les coûts (positifs, non nuls) d'une arête de $G$.
		Notons $\ell(\cdot)$ les rongeurs des chemins.
	
		\begin{numlem}
			\[
				\forall (u,v) \in E,\quad d(s,v) \le d(s, u) + c(u,v)
			.\]
		\end{numlem}
	
		\begin{prv}
			Soit $(u,v) \in E$.
			Soit $\gamma_u$ un plus court chemin de $s$ à $u$.
			Alors, $\gamma_u \cdot v$ est un chemin de $s$ à $v$ :
			\[
				\ell(\gamma_u \cdot v) = \ell(\gamma_u) + c(u,v) = d(s,u) + c(u,v) \ge d(s,v).
			\]
		\end{prv}
	
		\begin{numlem}
			Pour tout sommet $u$, la valeur de $\mu[u]$ est décroissant à mesure que l'algorithme s'exécute.
		\end{numlem}
	
		\begin{prv}
			Soit $\ubar{\mu}$ et $\bar\mu$ les valeurs de $\mu$ avant et après une opération $\textsc{Relâcher}(x,y)$.
			Pour tout sommet $v \neq y$, $\bar\mu[v] = \ubar\mu[v]$.
			De plus, par disjonction de cas,
			\begin{itemize}
				\item ou bien $\bar\mu[y] = \ubar\mu[y]$, \textsc{ok}.
				\item ou bien $\bar\mu[y] = \ubar\mu[x] + c(x,y)$ lorsque $\ubar\mu[x] + c(x,y) \le \ubar\mu[y]$, donc $\bar\mu[y] \le \ubar\mu[y]$, \textsc{ok}.
			\end{itemize}
		\end{prv}
	
		\begin{numlem}
			Supposons que l'algorithme ait initialisé $\mu$ de la manière suivante : \[
				\forall u \in V,\quad\quad \mu[u] = \begin{cases}
					+\infty & \text{ si } u \neq s\\
					0 & \text{ sinon}.
				\end{cases}
			\] Alors, tout au long de l'exécution de l'algorithme, pour tout sommet $u$, $\mu[u] \ge d(s,u)$.
		\end{numlem}
	
		\begin{prv}
			\begin{description}
				\item[Initialement] La propriété est vraie par hypothèse.
				\item[Hérédité] Supposons vrai jusqu'à un certain état $\ubar\mu$, pour une opération $\textsc{Relâcher}(x,y)$.
					Pour tout sommet $v \neq y$, $\ubar\mu[v] = \bar\mu[v] \ge d(s,v)$.
					De plus, par disjonction de cas,
					\begin{itemize}
						\item si $\bar\mu[y] = \ubar\mu[y] \ge d(s,y)$ ;
						\item sinon si $\ubar\mu[y] = \ubar\mu[x] + c(x,y) \ge d(s,x) + c(x,y) \ge d(s,y)$ par hypothèse de récurrence, puis par lemme 1.
					\end{itemize}
			\end{description}
		\end{prv}
	
		\begin{crlr}
			Si \guillemotleft~à un moment~\guillemotright\ $\mu[u] = d(s,u)$, alors \guillemotleft~pour toujours après~\guillemotright\ $\mu[u] = d(s,u)$.
			\qed
		\end{crlr}
	
		\begin{numlem}
			Si $(s, \ldots, u, v)$ est un plus court chemin de $s$ à $v$ tel que $\ubar\mu[u] = d(s,u)$ \guillemotleft~à un certain moment de l'exécution de l'algorithme.~\guillemotright\@ Notons $\bar\mu$ obtenu par $\textsc{Relâcher}(u,v)$.
		\end{numlem}
	
		\begin{prv}
			On a \[
				\bar\mu = \begin{cases}
					\ubar\mu[v] & \text{ si } \ubar\mu[v] < \ubar\mu[u] + c(u,v)\\
					\ubar\mu[u] + c(u,v) &\text{ sinon}.
				\end{cases}
			\]Par disjonction de cas,
			\begin{itemize}
				\item si $\ubar\mu[v] < \ubar\mu[u] + c(u,v) = d(s, u) + c(u,v) = d(s,v)$, et donc, en utilisant le lemme 3, $\bar\mu[v] = \ubar\mu[v] = d(s,v)$.
				\item sinon, $\bar\mu[v] = \ubar\mu[u] + c(u,v) = d(u,v) + c(u, v) = d(s,v)$.
			\end{itemize}
		\end{prv}
	
		\begin{numlem}
			Soit $(s=x_0, x_1, x_2, \ldots, x_n)$ un plus court chemin. Si on effectue des opérations \hbox{$\textsc{Relâcher}(x_i, x_{i+1})$} dans l'ordre $0 \to n - 1$, possiblement entremêlés avec d'autres opérations $\textsc{Relâcher}$, alors pour tout $i \in \llbracket 0,n \rrbracket$, $\mu_{\text{final}}[x_i] = d(s, x_i)$.
		\end{numlem}
	
		\begin{prv}[par récurrence]
			\begin{itemize}
				\item Initialement, $\mu[x_0] = d(s, x_0) = d(s,s)$.
				\item Et, pour tout les $i$ inférieurs stricts, $\mu[x_i] = d(s, x_i)$, on conclut par le lemme 4.
			\end{itemize}
		\end{prv}
	
		(De ce lemme découle l'algorithme de \textsc{Bellman-Ford}.)
	
		\begin{crlr}
			L'algorithme \textsc{Dijkstra} est correct.
		\end{crlr}
	
		\begin{prv}
			Soit $t \in V$, un sommet du graphe. Soit $(s = x_0, x_1, \ldots, x_{p-1}, x_p = t)$ un plus court chemin de $s$ à $t$. Montrons que $\mu_{\text{final}}[t] = d(s, t)$.
			En utilisant le lemme 5, il suffit de montrer que \textsc{Dijkstra} relâche les arêtes dans cet ordre.
			Supposons les sommets extraits $\mathrm{todo}$ dans l'ordre $x_0, \ldots, x_i$, pour $i \in \llbracket 0,p-1 \rrbracket$.
			Par l'absurde, supposons que \textsc{Dijkstra} sorte $x_k$ de $\mathrm{todo}$ pour $k \in \llbracket i+2, p \rrbracket$.
			\guillemotleft~À ce moment là,~\guillemotright\ on a \[
				d(s, x_k) \le \mu[x_k] \le \mu[x_{i+1}] \le d(s, x_{i+1}),
			\]d'après le lemme 5, ce qui est absurde ($k > i + 1$).
		\end{prv}
	
		\begin{crlr}
			L'algorithme $A^*$ est correct.
		\end{crlr}
	
		\begin{algorithm}[H]
			\centering
			\begin{algorithmic}[1]
				\Procedure{Relâcher}{$u,v$}
				\If{$\mu[v] > \mu[u] + c(u,v)$}
				\State $\mu[v] \gets \mu[u] + c(u,v)$
				\State $\pi[v] \gets u$
				\State $\eta[v] \gets \mu[v] + h(v)$
				\EndIf
				\EndProcedure
			\end{algorithmic}
			\caption{Algorithme $A^*$ (partiel)}
		\end{algorithm}
	
		\begin{prv}
			Par l'absurde, supposons que non.
			Soit $t \in V$, un sommet du graphe, tel que $\mu_{\text{final}}[t] \neq d(s,t)$.
			Donc $d = \mu_{\text{final}}[t] > d(s,t) = d^*$.
			Soit $(s = x_0, x_1, \ldots, x_{p-1}, x_p = t)$ un plus court chemin de $s$ à $t$ de longueur $d^*$.
			L'algorithme commence par visiter $x_0 = s$ et on relâche les arêtes sortantes.
			Alors, $\mu[x_i] = d(s, x_1)$ et $\eta[x_1] = \mu[x_1] + \mu[x_1] + h(x_1) \le d(s, x_1) + d(x_1, t) = d(s,t) = d^* < d$ par hypothèse.
			\guillemotleft~À ce state,~\guillemotright\ $\eta[t] = \mu[t] + h(t) \ge d + 0$.
			Ainsi, $x_1$ devrait être choisi avant $t$. À un tel moment, $\mu[x_1] = d(s, x_1)$, on relâche alors ses arêtes sortantes ; en particulier $x_1$ et $x_2$. Ceci assure alors que $\mu[x_2] = d(s, x_2)$, et $\eta[x_2] = \mu[x_2] + h(x_2) \le d(sn x_2) + d(x_2, t) \le d(s,t) = d^* < d$.
			\guillemotleft~De proche en proche,~\guillemotright\ alors que l'on choisit $x_{p-1}$ dans $\mathrm{todo}$, on a $\mu[x_{p-1}] = d(s, x_{p-1})$.
			On relâche alors $\mu[x_p] = d(s, x_p) = d^*$.
			Or, $d = \mu_{\text{final}}[t] \le \mu_{\text{à ce moment}}[t]$. Absurde.
		\end{prv}
	
		\begin{exm}[ré-entrée dans $\mathrm{todo}$]
			\begin{comment}
				     b (h = 6)
						/ \
				 1 /   \ 1
					/  3  \     5
				 s - - - a - - - - t
			        (h = 0)   (h = 0)
			\end{comment}
			Exécution de l'algorithme $A^*$ sur l'entrée ci-dessus.
			La pile $\mathrm{todo}$ est vaut donc $\cancel s, \cancel a, \cancel b, \cancel t, \cancel a$.
		\end{exm}
	}
	\def\addmacros#1{#1}
}
{
	\chap[3]{Diviser pour régner}
	\minitoc
	\renewcommand{\cwd}{../cours/annexeC/}
	\addmacros{
		\input{../cours/annexeC/l1.tex}
	}
	\def\addmacros#1{#1}
}
{
	\chap[4]{Lemme d'\textsc{Arden} et retour sur le théorème de \textsc{Kleene}}
	\minitoc
	\renewcommand{\cwd}{../cours/annexeD/}
	\addmacros{
		\begin{exm}[Lemme d'\textsc{Arden}]
			Soient $K$ et $L$ deux langages. Résoudre $X = K\cdot X \cup L$ pour $X$ un langage.
			(On trouve~$X = K^* \cdot L$.) On suppose que $\varepsilon \not\in K$.
			On procède par double-inclusion.
			\begin{itemize}
				\item[``$\supseteq$''] Soit $X$ un langage tel que $X = K\cdot X \cup L$.
					Montrons par récurrence \guillemotleft~si $w$ est un mot de $X$ de taille $n$, alors $w \in K^* \cdot L$.
					\begin{itemize}
						\item Si $n= 0$, alors $w \in L$ car $\varepsilon \not\in  K$.
							Ainsi, $w = \varepsilon \cdot w$ et $\varepsilon \in K^*$. On en déduit que $w \in K^* \cdot L$.
						\item Si $|w| = n$, alors
							\begin{itemize}
								\item si $w \in L$, alors $w = \varepsilon \cdot w$ et donc $w \in K^* L$.
								\item si $w = v \cdot w'$ où $v \in K$ et $w' \in X$, alors $|w'| < |w|$. Ainsi, par hypothèse de récurrence, $w' \in K^* \cdot L$. Ainsi, $v \cdot w' \in K^* \cdot L$.
							\end{itemize}
					\end{itemize}
					Ainsi, $X \subseteq K^* \cdot L$.
				\item[``$\subseteq$'']
					Soit $w \in K^* \cdot L$. Il existe donc $n \in \N$, $(v_1, \ldots, v_n) \in K^n$ et $w' \in L$ tels que $w = v_1 \cdot \ldots \cdot v_n \cdot  w'$.
					Alors, $w' \in X$ donc $v_n \cdot w' \in X$ donc \ldots donc $v_1 v_2 \ldots v_n w' \in X$.
					Ainsi, $w \in X$.
			\end{itemize}
		\end{exm}
	
		\begin{exm}
			On considère l'automate ci-dessous.
			\begin{figure}[H]
				\centering
				\tikzfig{auto-ex}
				\caption{Automate exemple ($\mathcal{A}$)}
			\end{figure}
			On pose $X_i = \mathcal{L}\big((\Sigma, \mathcal{Q}, \{i\}, F, \delta)\big)$, où $x_i$ est l'unique point de départ.
			Ainsi, $\mathcal{L}(\mathcal{A}) = \bigcup_{i \in  I} X_i$.
			Déterminons les valeurs de $X_1$, $X_2$ et $X_3$.
			On applique un algorithme similaire au \guillemotleft~pivot de Gau\ss.~\guillemotright\ 
	
			\begin{align*}
				\left.\begin{array}{rl}
					X_1 &= \{a\} \cdot X_2 \cup \{a\} X_1\\
					X_2 &= \{b\} \cdot X_1 \cup \{a\} \cdot X_3 \cup \{\varepsilon\}\\
					X_3 &= \{b\} X_3 \cup \{\varepsilon\}
				\end{array}\right\}
				\iff& 
				\begin{cases}
					X_1&= \{a\}^* \cdot \{a\} \cdot X_2\\
					X_2&= \mathcal{L}(ba^* \cdot a) X_2 \cup \{a\} X_3 \cup \{\varepsilon\}\\
					X_3&= \{b\} \cdot X_3 \cup \{\varepsilon\}
				\end{cases}\\
				\iff& 
				\begin{cases}
					X_1&= \mathcal{L}(a^* \cdot a) X_2\\
					X_2&= \mathcal{L}\big((b\cdot a^* \cdot a)^*\big) \cdot \big(\{a\} X_3 \cup \{\varepsilon\}\big)\\
					X_3&= \{b\} X_3 \cup \{\varepsilon\}
				\end{cases}\\
				\iff& \begin{cases}
					X_1&= \mathcal{L}(a^* \cdot a) X_2\\
					X_2&= \mathcal{L}\big((b\cdot a^* \cdot a)^*\big) \cdot \big(\{a\} X_3 \cup \{\varepsilon\}\big)\\
					X_3&= \mathcal{L}(b^*)
				\end{cases} \\
				\iff& \begin{cases}
					X_1&= \mathcal{L}(a^* \cdot a) X_2\\
					X_2&= \mathcal{L}\big((ba^*a)^* \cdot (ab^*  \mid \varepsilon)\big)\\
					X_3&= \mathcal{L}(b^*)
				\end{cases} \\
				\iff& \begin{cases}
					X_1&= \mathcal{L}\big(a^* \cdot a \cdot (ba^*a)^* \cdot (ab^*  \mid \varepsilon)\big)\\
					X_2&= \mathcal{L}\big((ba^*a)^* \cdot (ab^*  \mid \varepsilon)\big)\\
					X_3&= \mathcal{L}(b^*)
				\end{cases}
			\end{align*}
		\end{exm}
	
		On peut généraliser la méthode employée dans l'exemple précédent pour montrer que tout langage reconnaissable est régulier.
	}
	\def\addmacros#1{#1}
}
{
	\chap[5]{Tas et files de priorités}
	\minitoc
	\renewcommand{\cwd}{../cours/annexeE/}
	\addmacros{
		L'objectif d'une file de priorité est de récupérer l'élément de priorité minimale.
		On organise cette structure de données sous forme d'un arbre tournois.\footnote{Un arbre tournois n'est pas un arbre binaire de recherche.}
		Un arbre tournois est un arbre dont la priorité d'un nœud est supérieur à celle de ses fils.
		On impose une structure supplémentaire, l'arbre doit être parfait : l'arbre est complet jusqu'à l'avant dernier niveau, où il est replis à gauche.
		 On définit plusieurs opérations sur cette file de priorité (de type \texttt{fp}, où les éléments sont de type \texttt{elem}) :
		\begin{itemize}
			\item $\texttt{insérer} : \texttt{fp} \to \texttt{elem} \to \texttt{fp}$ qui insère un élément,
			\item $\texttt{lire\_min} : \texttt{fp} \to \texttt{elem}$ qui récupère l'élément de priorité minimale,
			\item $\texttt{supprimer\_min} : \texttt{fp} \to \texttt{fp}$ qui supprime l'élément de priorité minimale,
			\item ($\texttt{diminuer\_priorité} : \texttt{fp} \to \texttt{elem} \to \texttt{fp}$),\footnote{Cette opération est parfois omise car trop compliquée à implémenter.}
			\item $\texttt{créer} : (\:) \to \texttt{fp}$.
		\end{itemize}
		On définit un type \texttt{btree}, représentant un arbre binaire, et on implémente les opérations ci-dessous en \textsc{OCaml}.
		\begin{lstlisting}[language=caml,caption=Définition du type \texttt{btree}]
	type 'a btree =
	| Node of 'a * 'a btree * 'a btree
	| Empty
		\end{lstlisting}
		Pour l'opération \texttt{créer}, on retourne \texttt{Empty} (cela donne une complexité en $\Theta(1)$). 
		Pour l'opération \texttt{insérer}, on insère l'élément comme feuille (de manière à conserver la propriété de l'arbre parfait), et on inverse le nœud avec son parent jusqu'à ce que la propriété soit vérifiée ($\Theta(\log_2 n)$).
		Pour l'opération \texttt{lire\_min}, on lit la racine ($\Theta(1)$).
		Pour l'opération \texttt{supprimer\_min}, on permute la racine et le dernier nœud (\textit{i.e.} le nœud le plus à droite de hauteur maximale), et on restore la structure d'arbre tournois en permutant un nœud et son fils de valeur minimale, et en répétant ($\Theta(\log_2 n)$).
		Pour trouver le dernier nœud, on garde en mémoire cet emplacement.
		On peut aussi implémenter cet algorithme avec un tableau ($\triangleright$ \textsc{tp}), ou avec une liste triée (mais la complexité est moins bien).
	}
	\def\addmacros#1{#1}
}
{
	\chap[6]{Arithmétique}
	\minitoc
	\renewcommand{\cwd}{../cours/annexeF/}
	\addmacros{
		Un des premiers algorithmes codé est l'algorithme d'Euclide pour calculer le \textsc{pgcd}. Pour $a \neq 0$, on a $a \wedge 0 = a$ et $a \wedge b = b \wedge (a\ \mathrm{mod}\ b)$.
		On peut le coder en \textsc{OCaml} avec la fonction \texttt{euclid} suivante.
	
		\begin{lstlisting}[language=caml,caption=Algorithme d'Euclide calculant le \textsc{pgcd}]
	let rec euclid (a: int) (b: int): int =
		(* Hyp: a >= b et a != 0 *)
		if b = 0 then a
		else euclide b (a mod b)
		\end{lstlisting}
		
		Quelle est la complexité de cet algorithme ?
		On représente le nombre d'appels récursifs à \texttt{euclid}, et on devine une courbe logarithmique.
		En notant $(u_n)$ les divisions euclidiennes réalisées et $(q_n)$ les quotients, ainsi, on $u_n = q_{n-1} \cdot u_{n-1} + u_{n-2}$.
		Alors, $\texttt{euclid}(u_n, u_{n-1}) = \cdots = \texttt{euclid}(u_3, u_2) = \texttt{euclid}(u_2, u_1) = \texttt{euclid}(u_1, u_0)$.
	
		En fixant la complexité, on cherche les valeurs de $(u_n)$ maximisant les appels récursifs.
		On peut montrer par récurrence que si $\texttt{euclid}(a,b)$ conduit à $n$ appels récursifs de \texttt{euclid}, alors $a \ge F_n$ et $b \ge F_{n-1}$, où $(F_n)_{n\in\N}$\/ est la suite de Fibonacci.
	
		En effet, soit un tel couple $(a,b)$. Alors, $(b, a\ \mathrm{mod}\ b)$ conduit à $n - 1$ appels récursifs donc~$b \ge F_{n-1}$ et~$a\ \mathrm{mod}\ b \ge F_{n-2}$ par hypothèse de recurrence.
		Et, $a = bq + (a\ \mathrm{mod}\ b)$ et donc $a \ge F_{n-1} + F_{n-2} = F_n$.
	
		De plus, pour tout $n \in \N \setminus \{0,1\}$, $F_n \ge \varphi^{n-2}$ où $\varphi$ est le nombre d'or.\footnote{C'est la solution positive de $X^2 - X - 1 = 0$.}
		En effet, $F_2 = 1 \ge \varphi^0 = 1$ et $F_3 = 2 \ge \varphi^1 = \varphi = (1 + \sqrt{5}) / 2$. Et, $F_n = F_{n-1} + F_{n-2} \ge \varphi^{n-3} + \varphi^{n-4} \ge \varphi^{n-4}(1 + \varphi) \ge \varphi^{n-2}$.
	
		Soient $(p,q)$, où $p \ge q$, une entrée de l'algorithme d'Euclide. Si l'appel $\texttt{euclid}(p,q)$ conduit à plus de $\left\lceil \log_\varphi p \right\rceil + 4$ appels, alors $p \ge F_{\left\lceil \log_\varphi p \right\rceil + 4} \ge \varphi^{\left\lceil \log_\varphi p \right\rceil + 4 - 2} > \varphi^{\log_\varphi p} = p$, ce qui est absurde.
	
		Ceci conduit à une complexité en $\mathcal{O}(\log p)$.
	
		\bigskip
	
		Soit $n$ un entier premier.
		Pour l'algorithme RSA, on cherche un inverse de $a \in \sfrac{\Z}{n\Z}$ : on cherche $b \in \sfrac\Z{n\Z}$ tel que $ab \equiv 1 \mod 1$. D'après le théorème de Bézout, on a $au + nv = 1$ car $a \wedge n = 1$. L'inverse est $v$. D'où l'importance des coefficients de Bézout.
	
		Comment calculer les coefficients de Bézout ?
		On peut utiliser l'algorithme d'Euclide.
		On pose $r_n$\/ la valeur de \texttt{a} après $n$ appels récursifs.
	
		\begin{table}[H]
			\centering
			\begin{tabular}{c|c|c|c|c}
				$r_i$ & $u_i$ & & $v_i$ &\\ \hline \hline
				$r_0 = a$ & $1$ & $a$ & $0$ & $b$\\
				$r_1 = b$ & $0$ & $b$ & $1$ & $a$\\
				$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
				$r_{i-2}$ & $u_{i-2}$ & $a$ & $v_{i-2}$ & $b$\\
				$r_{i-1}$ & $u_{i-1}$ & $a$ & $v_{i-1}$ & $b$ \\
			\end{tabular}
			\caption{Valeurs de $r_i$ avec invariant $r_i = a u_i + b v_i$}
		\end{table}
	
		Alors,
		\begin{align*}
			r_i &= u_{i-2} a + v_{i-2} b - (r_{i-2} / r_{i-1}) (u_{i-1}a + v_{i-1} b)\\
			&= \big(u_{i-2} - (r_{i-2}/r_{i-1}) u_{i-1}\big) a + \big(v_{i-2} - (r_{i-2}/r_{i-1}) v_{i-1}\big) b \\
		\end{align*}
		Ainsi, on a bien $\mathrm{pgcd}(a,b) = u_{n-1} a + v_{n-1} b$.
	}
	\def\addmacros#1{#1}
}
{
	\chap[7]{Arbres rouges-noirs}
	\minitoc
	\renewcommand{\cwd}{../cours/annexeG/}
	\addmacros{
		Un arbre rouge-noir est un cas particulier des arbres binaires de recherches.
		On l'utilise notamment pour représenter des ensembles, on veut donc réaliser deux opérations simples : l'insertion et le test d'appartenance.
		Initialement, on pense représenter un ensemble par une liste triée.
		Mais, on utilise plutôt un arbre binaire pour représenter des données avec une hauteur logarithmique, contrairement à une hauteur linéaire.
		Les arbres binaires de recherches sont des arbres dans lesquels ont peut réaliser une dichotomie.
		\begin{lstlisting}[language=caml,caption=Arbre binaire de recherche]
	type 'a btree = E | N of 'a * 'a btree * 'a btree
	
	let rec mem (x: 'a) (t: 'a btree): bool =
		match t with
		| E -> false
		| N(y, g, d) ->
				if x < y      then mem x g
				else if x = y then true
				else               mem x d
	
	let rec insere (x: 'a) (t: 'a btree): 'a btree =
		match t with
		| E -> false
		| N(y, g, d) ->
				if x < y      then N(y, insere x g, d)
				else if x = y then t
				else               N(y, g, insere x d)
		\end{lstlisting}
		La fonction \texttt{mem} permet de réaliser ce test d'appartenance et la fonction \texttt{insere} insère l'insertion dans l'arbre.
		Ainsi, on peut représenter un ensemble avec le type \texttt{'a btree}.
	
		Mais, cet arbre peut être déséquilibré, et l'utilisation de la dichotomie ne donne pas de résultats très avantageux.
		On utilise donc un arbre \textit{auto-équilibrant}, comme les \textsc{avl} du 1er \textsc{dm}. Pour les \textsc{avl}, la différence de hauteur est $-1$, $0$ ou $1$.
	
		On introduit donc le concept d'arbre rouge-noir.
		Un arbre rouge-noir est un arbre parfait, qui a une certaine \guillemotleft~élasticité.~\guillemotright\@
		On colorie chaque nœuds pour imposer des contraintes sur cette élasticité.
		Les branches de l'arbre a une longueur de rupture.
		Un arbre contenant uniquement des nœuds noirs est un arbre parfait.
		Et, entre deux nœuds noirs, on peut insérer un nœud rouge.
		Un arbre rouge-noir vérifie donc les trois propriétés suivantes :
		\begin{enumerate}[label=(\textit{\alph*})]
			\item la racine est noire,
			\item le père d'un nœud rouge est noir,
			\item la hauteur noir de chaque feuille externe est constante. \hfill [important]
		\end{enumerate}
		Une \textit{feuille externe} est, dans le code \textsc{OCaml}, l'expression \texttt{E} ; et, la \textit{hauteur noir} d'une feuille externe est le nombre de nœuds noirs depuis la racine.
		On définit la \textit{hauteur noir} d'un arbre comme la hauteur noir de chaque feuille externe (qui est constante).
	
		Le problème est l'insertion d'un nœud.
		Insérer un nœud noir est, en général, plus dangereux car il modifie la hauteur noir de tout l'arbre.
		On préfère donc insérer un nœud rouge, sauf dans le cas de la racine.
	
		On considère donc la propriété (\textit{c}) comme invariante. En effet, corriger un arbre pour valider la propriété (\textit{a}) ou la propriété (\textit{b}) est bien plus simple.
	
		On traite tous les cas dans le diaporama sur \textit{cahier-de-prépa}, et on réalise l'exemple sur les lettres A, L, G, O, R, I, T, H, M, E.
	
		\bigskip
		
		Pour supprimer un nœud dans un arbre binaire classique, on peut le remplacer par le maximal de son sous-arbre droit, ou le minimum de son sous-arbre gauche. Si on supprime un nœud ayant un seul fils, on n'a qu'à re-brancher le sous-arbre.
		Pour les arbres rouges-noirs, c'est supprimer un nœud noir qui pose problème.
		Pour cela, on introduit les nœuds doublement noirs, qui comptent pour deux dans la hauteur noir.
		Ainsi, on supprime le nœud noir et on remplace les autres nœuds par des nœuds doublement noirs.
		L'algorithme n'a donc qu'à faire remonter le nœud doublement noir, jusqu'à la racine, où il sera transformé en nœud simplement noir.
	
		Un arbre de hauteur $h$ a une hauteur noir $\mathrm{bh} \ge h / 2$. Et, la taille, \textit{i.e.} le nombre de nœuds, est supérieure à $2^{\mathrm{bh}} - 1$.
		On conclut que $h \le 2 \log_2(\mathrm{taille} + 1)$.
		De même par la propriété (\textit{c}) permet de conclure que $h = \Theta(\log_2 \mathrm{taille})$.
	}
	\def\addmacros#1{#1}
}
{
	\chap[8]{Complexité moyenne}
	\minitoc
	\renewcommand{\cwd}{../cours/annexeH/}
	\addmacros{
		Dans les annexes et cours précédents, on a vu la complexité \guillemotleft~pire cas~\guillemotright\ et la complexité amortie.
		On considère les nombres d'opérations possibles pour toute entrée de taille $n$.
		La complexité \guillemotleft~pire cas~\guillemotright\ est la complexité obtenue en prenant le $\max$ d'opération possibilité.
		Pour la complexité moyenne, on suppose que chaque ensemble d'entrée de taille $n$ est munit d'une probabilité $P_n$.
		Par exemple, on considère qu'une entrée est une permutation de $n$ éléments, \textit{i.e.}\ un élément de $\mathfrak{S}_n$.
		On suppose que chaque entrée arrive avec équiprobabilité. Ainsi, $\forall \sigma \in \mathfrak{S}_n$, $P_n(\sigma) = 1/n!$.
		Ainsi, on a \[
			C_{\max}(n) = \max_{\sigma \in \mathfrak{S}_n} C(s) \text{ et } C_{\mathrm{moy}} = \sum_{\sigma \in \mathfrak{S}_n} P(\sigma) \cdot C(\sigma)
		.\]
		La complexité moyenne est la moyenne des complexité pondérées par les probabilités.
	
		\begin{exm}
			On considère l'algorithme ci-dessous.
			\begin{algorithm}[H]
				\centering
				\begin{algorithmic}[1]
					\Entree $\sigma \in \mathfrak{S}_n$ et $i \in \llbracket 1,n \rrbracket$
					\Sortie $j \in \llbracket 1,n \rrbracket$ tel que $\sigma(j) = i$.
					\For{$j \in \llbracket 1,n \rrbracket$}
					\If{$\sigma(j) = i$} \Return $j$
					\EndIf
					\EndFor
				\end{algorithmic}
				\caption{Calcul d'inverse d'une permutation}
			\end{algorithm}
			\noindent
			On munit $\mathfrak{S}_n$ de la probabilité uniforme.
			Soit $i \in \llbracket 1,n \rrbracket$.
			Notons, pour tout $j \in \llbracket 1,n \rrbracket$, $\mathfrak{S}_n^j = \{\sigma \in \mathfrak{S}_n  \mid \sigma(j) = i\}$.
			Remarquons que $\mathfrak{S}_n = \bigcupdot_{j=1}^n \mathfrak{S}_n^j$.
			Ainsi,
			\begin{align*}
				C_{\mathrm{moy}} &= \sum_{j=1}^n \sum_{\sigma \in \mathfrak{S}_n^j}P_n(\sigma) C(\sigma)\\
				&= \sum_{j=1}^n j \times \frac{|\mathfrak{S}_n^j|}{n!}\\
				&= \sum_{j=1}^n j \times \frac{(n+1)!}{n!}\\
				&= \frac{1}{n} \cdot \frac{n(n+1)}{2}\\
				&= \frac{n+1}{2}
			\end{align*}
		\end{exm}
	}
	\def\addmacros#1{#1}
}
{
	\chap[9]{Preuves de correction pour les fonctions récursives}
	\minitoc
	\renewcommand{\cwd}{../cours/annexeI/}
	\addmacros{
		On considère l'insertion dans un arbre binaire de recherche.
		Démontrons qu'elle est correcte.
		On adopte les notations de l'annexe G sur les arbres rouges-noirs.
		Montrons que, pour tout ABR $t$, et pour tout étiquette $e \in \mathds{E}$, 
		\[
			\mathrm{\acute{e}tiquettes}(\texttt{insertion}(t, x)) = \mathrm{\acute{e}tiquettes}(t) \cup \{x\}
		.\]
		Montrons le par induction.
		\begin{enumerate}
			\item Si $t = \texttt{E}$. Soit $x \in \mathds{E}$ : \[
					\mathrm{\acute{e}tiquettes}(\texttt{insertion}(\texttt{E},x)) = \mathrm{\acute{e}tiquettes}(N(x, \texttt{E},\texttt{E})) = \{x\} = \mathord{\underbrace{\mathrm{\acute{e}tiquettes}(\texttt{E})}_{\O}} \cup \{x\}
				.\]
			\item Si $t = \texttt{N}(y, g, d)$. Soit $x \in \mathds{E}$.
				\begin{itemize}
					\item si $x < y$, alors
						\begin{align*}
							\mathrm{\acute{e}tiquettes}(\texttt{insertion}(t,x))
							&= \mathrm{\acute{e}tiquettes}(\texttt{N}(y, \texttt{insertion}(g,x), d)) \\
							&= \{x\} \cup \mathrm{\acute{e}tiquettes}(\texttt{insertion}(g,x)) \cup \mathrm{\acute{e}tiquettes}(d) \\
							&= \{y\}  \cup \mathrm{\acute{e}tiquettes}(g) \cup \{x\} \cup \mathrm{\acute{e}tiquettes}(d) \\
							&= \mathrm{\acute{e}tiquettes}(\texttt{N}(y,g,d)) \cup \{x\} \\
							&= \mathrm{\acute{e}tiquettes}(t) \cup \{x\} \\
						\end{align*}
					\item on procède de même pour les autres cas.
				\end{itemize}
		\end{enumerate}
		On procède de même pour les autres propriétés.
	}
	\def\addmacros#1{#1}
}
